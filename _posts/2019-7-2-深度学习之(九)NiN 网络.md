---
layout:     post
title:      深度学习之(九)NiN 网络
#subtitle:  
date:       2019-7-2
author:     feizaipp
header-img: img/post-bg-desk.jpg
catalog: true
tags:
    - DeepLeaning
    - AI
---

> [我的博客](http://feizaipp.github.io)

# 1. 概述
&#160; &#160; &#160; &#160;NiN 即网络中的网络(Network In Network)。前面几章介绍的 LeNet 、 AlexNet 和 VGG 在设计上都是先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。其中， AlexNet 和 VGG 对 LeNet 的改进主要在于如何对这两个模块加宽（增加通道数）和加深。而本章的主角 NiN 网络它提出了另外一个思路，即串联多个由卷积层和全连接层构成的小网络来构建一个深层网络。

# 2. NiN 网络块
&#160; &#160; &#160; &#160;我们知道，卷积层的输入和输出通常是四维数组(样本，通道，高，宽)，而全连接层的输入和输出则通常是二维数组(样本，特征)。如果想在全连接层后再接上卷积层，则需要将全连接层的输出变换为四维。在卷积神经网络一章中介绍了 1×1 卷积层。它可以看成全连接层，其中空间维度(高和宽)上的每个元素相当于样本，通道相当于特征。因此， NiN 使用 1×1 卷积层来替代全连接层，从而使空间信息能够自然传递到后面的层中去。

&#160; &#160; &#160; &#160;NiN 块是 NiN 网络的基础块。它由一个卷积层加两个充当全连接层的 1×1 卷积层串联而成。其中第一个卷积层的超参数可以自行设置，而第二和第三个卷积层的超参数一般是固定的。

# 3. NiN 模型
&#160; &#160; &#160; &#160;NiN 使用卷积窗口形状分别为 11×11 、 5×5 和 3×3 的卷积层，相应的输出通道数与 AlexNet 中的一致。每个 NiN 块后接一个步幅为 2 、窗口形状为 3×3 的最大池化层。

&#160; &#160; &#160; &#160;NiN 去掉了 AlexNet 最后的 3 个全连接层，取而代之地， NiN 使用了输出通道数等于标签类别数的 NiN 块，然后使用全局平均池化层对每个通道中所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN 的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计有时会造成获得有效模型的训练时间的增加。